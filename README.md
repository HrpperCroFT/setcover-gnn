# SetCover-GNN

Графовая нейронная сеть, решающая задачу Set Cover, используя обучение без учителя.

## Постановка задачи

Задача Set Cover является одной из задач комбинаторной оптимизации. Формулируется задача так:

Есть универсальное множество U и набор его подмножеств $s_1, s_2, ... s_k$, каждый элемент универсального множества содержится хотя бы в одном из подмножеств набора. Требуется найти наименьший по размеру поднабор этих подмножеств, что объединение всех подмножеств поднабора даст множество U.

Данная задача является NP трудной и не имеет на текущий момент решений, которые могут дать за сколько-нибудь нормально ограниченное время ответ. Но вместо этого есть решения, что могут дать ответ приближенный к реальному, то есть не минимальный по размеру поднабор, но достаточно малый. Данная задача имеет применение, например, при составлении расписаний для персонала.

Кроме того, есть задача QUBO (Quadratic Unconstrained Binary Optimization), которая формулируется так:

Существует симметричная квадратная матрица $A \in R^{n*n}$. Через неё определяется функция $f_A : {0, 1}^n \xrightarrow{} R, f_A(x) =x^T A x$. Требуется найти глобальный минимум этой функции.
Задача Set Cover при этом имеет способ сведения к QUBO, что описан, например, [здесь](https://arxiv.org/pdf/2302.11185).
Саму задачу QUBO можно решить с помощью графовых нейронных сетей, что описано [здесь](https://arxiv.org/pdf/2107.01188). Далее идея была развита и архитектура графовых нейронных сетей была улучшена для решения конкретной задачи в [этой статье](https://arxiv.org/pdf/2407.16468).
Таким образов, есть архитектура нейронной сети, что может решать задачу Set Cover после соответствующего преобразования.

## Метрики

Основная метрика, используемая в модели — это функция $f_A$, немного модифицированная. Во время обучения модели получаются значения вероятностей того, равны ли значения переменных (т.е. координат вектора x) единице. Затем они передаётся в $f_A$, добавляется штраф $(1 - probs) * probs$, чтобы вероятности не были слишком близки к 0.5 и более чётко определяли значения переменных, сам штраф умножается на коэффициент, зависящий линейно от эпохи обучения. Полученный loss используется для обучения. К сожалению, трудно сказать хорошие значения метрики. Но немного дополнительно:

Кроме самого loss берутся значения метрики после округленния x, т.е. преобразования в 0 и 1. Это значение соответствует результатам функции, описаной [здесь](https://arxiv.org/pdf/2302.11185), с помощью которой задача как раз сводится к QUBO. Разница только в константном мономе. При логировании он добавляется, поэтому результат можно интерпретировать нормально. В идеале он должен быть около 0, во всяком случае не больше количества подмножеств, умноженного на специальный коэффициент.

## Валидация

Поскольку модель предполагает обучение без учителя, в итоге валидация происходит просто сравнением результата асимптотического алгоритма (бейзлайн) с решением, найденным моделью.

## Данные

По итогу данные просто генерируются. Нет, на деле есть датасет, состоящий, правда, также из сгенерированных данных, на котором можно проверить модель, но обучение (и инференс) модели получается слишком длинным, чтобы можно было проверить результат даже на одном тесте. Так или иначе, датасет загружен [отсюда](https://web.archive.org/web/20090224183054/http://www.nlsde.buaa.edu.cn/~kexu/benchmarks/set-benchmarks.htm).

# Моделирование

## Бейзлайн

Для бейзлайна взят жадный алгоритм — брать из набора каждый раз такое подмножество, что покрывает наибольшее количество из ещё непокрытых элементов.

## Основная модель

Модель взята из [этой статьи](https://arxiv.org/pdf/2407.16468), переделана под конкретно Set Cover.

# Установка

Установка через пакетный менеджер uv:

```powershell
uv sync
```

Для установки uv нужно ввести команду:

```powershell
pip install uv
```

Если нужно проверить тесты, рекомендуется написать вот такую команду:

```powershell
uv sync --editable --extra test
```

Активировать venv:

```powershell
.venv\Scripts\activate.ps1
```

И затем можно запустить тесты с hydra, указав в конфиге то, что нужно:

```powershell
python tests\test_with_hydra.py
```

Перед тестированием можно скачать данные с помощью запуска следующего скрипта:

```powershell
python tests\download_data.py
```

Внимание: на этих данных модель не может вычислять достаточно быстро. К сожалению, размер матрицы равен квадрату стороны, а сторона матрицы не меньше, чем количество элементов в универсальном множестве. В общем, это очень большое число. Поэтому используем сгенерированные данные, так или иначе, данные все здесь сгенерированы, т.к. в открытом доступе нет данных из жизни для этой задачи.

# Использование (тренировка и инференс)

Данный пакет можно использовать в своих проектах для решения задачи Set Cover в некотором виде. Смотри файл scripts\solve_local_file.py для более наглядного понимания.
